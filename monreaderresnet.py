# -*- coding: utf-8 -*-
"""MonReaderResnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IMf4_42a9usibNhQYoUXo5gXDcHNsCrA

# Single Image prediction using ResNet

## Data Preparation
"""

#mount google drive in colab
from google.colab import drive
drive.mount('/content/drive')

#update file paths
train_data_dir = '/content/drive/My Drive/images/images/training'
test_data_dir = '/content/drive/My Drive/images/images/testing'
test_set_data_dir = '/content/drive/My Drive/images/images/test_set'

from tensorflow.keras.preprocessing.image import ImageDataGenerator
#use ResNet50
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.callbacks import EarlyStopping
#set up data generators
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,  # Preprocesses the data using ResNet50's method
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
test_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input  # Apply ResNet50 preprocessing
)

# Load images from directory
train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(224, 224),  # Ensure this matches ResNet's expected input size
    batch_size=32,
    class_mode='binary',  # or 'categorical'
    shuffle=True
)

validation_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(224, 224),  # Ensure this matches ResNet's expected input size
    batch_size=32,
    class_mode='binary',  # or 'categorical'
    shuffle=True
)

test_generator = test_datagen.flow_from_directory(
    test_set_data_dir,  # replace with your test data path
    target_size=(224, 224),  # or the input size of your model
    batch_size=1,  # or a batch size that divides your total number of test samples
    class_mode='binary',  # or 'categorical' for multi-class
    shuffle=False)

"""## Build and Train Resnet Model"""

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.callbacks import EarlyStopping

#load pretrained model
base_model = ResNet50(weights='imagenet', include_top=False)
#add custom layers
x = base_model.output
x = GlobalAveragePooling2D()(x)  # Add a global spatial average pooling layer

# Add a fully connected layer
x = Dense(1024, activation='relu')(x)

# Add a logistic layer for binary classification
predictions = Dense(1, activation='sigmoid')(x)

# The model we will train
model = Model(inputs=base_model.input, outputs=predictions)

#freeze layers of pretrained model
for layer in base_model.layers:
    layer.trainable = False
# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=3,restore_best_weights=True)
#compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
#train the model
history = model.fit(
    train_generator,
    epochs=25,
    callbacks=[early_stopping],
    validation_data=validation_generator
)

#plot the loss and accuracy
import matplotlib.pyplot as plt

# Assuming 'history' is the result returned by the fit function
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

#Fine-tuning
import tensorflow as tf
# Unfreeze some top layers of the model
for layer in base_model.layers[-20:]:
    layer.trainable = True

# Re-compile the model for fine-tuning
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Continue training
history_fine = model.fit(
    train_generator,
    epochs=5,
    validation_data=validation_generator
)

import numpy as np
#Evaluate model on test set
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {test_accuracy}")
#calculate f1 score
from sklearn.metrics import precision_score, recall_score, f1_score

# Predictions
test_predictions = model.predict(test_generator)
test_predictions_binary = (test_predictions > 0.5).astype(np.int64)

# True labels
true_labels = test_generator.classes

# Calculate precision, recall, and F1 score
precision = precision_score(true_labels, test_predictions_binary)
recall = recall_score(true_labels, test_predictions_binary)
f1 = f1_score(true_labels, test_predictions_binary)

print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")

model.save('/content/resnet2.h5')

