{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecfc929",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8725853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Richard Han\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Richard Han\\AppData\\Local\\Temp\\ipykernel_17220\\2373802186.py:5: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "Number of flip images in training set: 0\n",
      "Number of nonflip images in training set: 0\n",
      "Number of flip images in testing set: 290\n",
      "Number of nonflip images in testing set: 307\n"
     ]
    }
   ],
   "source": [
    "#suppress tensorflow warnings\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)  # Suppress all warnings\n",
    "\n",
    "#count number of images\n",
    "\n",
    "import os\n",
    "\n",
    "def count_images(directory):\n",
    "    # Count the number of files in the given directory\n",
    "    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
    "\n",
    "# Set the paths to your flip and nonflip directories\n",
    "flip_dir = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images_original\\\\images\\\\training\\\\flip'\n",
    "nonflip_dir = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images_original\\\\images\\\\training\\\\notflip'\n",
    "\n",
    "# Count images in each directory\n",
    "num_flip_images = count_images(flip_dir)\n",
    "num_nonflip_images = count_images(nonflip_dir)\n",
    "\n",
    "print(f\"Number of flip images in training set: {num_flip_images}\")\n",
    "print(f\"Number of nonflip images in training set: {num_nonflip_images}\")\n",
    "\n",
    "# Set the paths to your flip and nonflip directories\n",
    "flip_dir_test = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images_original\\\\images\\\\testing\\\\flip'\n",
    "nonflip_dir_test = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images_original\\\\images\\\\testing\\\\notflip'\n",
    "\n",
    "# Count images in each directory\n",
    "num_flip_images_test = count_images(flip_dir_test)\n",
    "num_nonflip_images_test = count_images(nonflip_dir_test)\n",
    "\n",
    "print(f\"Number of flip images in testing set: {num_flip_images_test}\")\n",
    "print(f\"Number of nonflip images in testing set: {num_nonflip_images_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6391c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Split the testing set of images into a validation set and a test set\n",
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "# source_dir = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images\\\\images\\\\testing'  # Replace with the path to your current 'testing' folder\n",
    "# test_dir = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images\\\\images\\\\test_set'  # Replace with the path to your new test set folder\n",
    "\n",
    "# # Categories\n",
    "# categories = ['flip', 'notflip']\n",
    "\n",
    "# #create test folder\n",
    "# if not os.path.exists(test_dir):\n",
    "#     os.mkdir(test_dir)\n",
    "\n",
    "# for category in categories:\n",
    "#     category_dir = os.path.join(test_dir, category)\n",
    "#     if not os.path.exists(category_dir):\n",
    "#         os.mkdir(category_dir)\n",
    "\n",
    "# #split the data\n",
    "# split_ratio = 0.5  # Adjust as needed\n",
    "\n",
    "# for category in categories:\n",
    "#     category_path = os.path.join(source_dir, category)\n",
    "#     images = os.listdir(category_path)\n",
    "#     random.shuffle(images)  # Shuffle the images\n",
    "    \n",
    "#     # Calculate the split index\n",
    "#     split_index = int(len(images) * split_ratio)\n",
    "    \n",
    "#     # Select images to move\n",
    "#     images_to_move = images[:split_index]\n",
    "    \n",
    "#     # Move selected images to the test folder\n",
    "#     for image in images_to_move:\n",
    "#         src_path = os.path.join(category_path, image)\n",
    "#         dest_path = os.path.join(test_dir, category, image)\n",
    "#         shutil.move(src_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a422e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flip images in validation set: 0\n",
      "Number of nonflip images in validation set: 0\n",
      "Number of flip images in test set: 0\n",
      "Number of nonflip images in test set: 0\n"
     ]
    }
   ],
   "source": [
    "#count how many images in testing set and test_set\n",
    "# Set the paths to your flip and nonflip directories\n",
    "flip_dir_test = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images\\\\images\\\\testing\\\\flip'\n",
    "nonflip_dir_test = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images\\\\images\\\\testing\\\\notflip'\n",
    "\n",
    "# Count images in each directory\n",
    "num_flip_images_test = count_images(flip_dir_test)\n",
    "num_nonflip_images_test = count_images(nonflip_dir_test)\n",
    "\n",
    "print(f\"Number of flip images in validation set: {num_flip_images_test}\")\n",
    "print(f\"Number of nonflip images in validation set: {num_nonflip_images_test}\")\n",
    "\n",
    "# Set the paths to your flip and nonflip directories\n",
    "flip_dir_test = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images\\\\images\\\\test_set\\\\flip'\n",
    "nonflip_dir_test = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images\\\\images\\\\test_set\\\\notflip'\n",
    "\n",
    "# Count images in each directory\n",
    "num_flip_images_test = count_images(flip_dir_test)\n",
    "num_nonflip_images_test = count_images(nonflip_dir_test)\n",
    "\n",
    "print(f\"Number of flip images in test set: {num_flip_images_test}\")\n",
    "print(f\"Number of nonflip images in test set: {num_nonflip_images_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e7c8d2",
   "metadata": {},
   "source": [
    "# Single Image Prediction using Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858deb20",
   "metadata": {},
   "source": [
    "## Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3572934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #use ResNet50\n",
    "# from tensorflow.keras.applications import ResNet50\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "# from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# train_data_dir = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images\\\\images\\\\training' # replace with your path\n",
    "# test_data_dir = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images\\\\images\\\\testing'  # replace with your path\n",
    "# test_set_data_dir = 'C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\images\\\\images\\\\test_set'\n",
    "\n",
    "# #set up data generators\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     preprocessing_function=preprocess_input,  # Preprocesses the data using ResNet50's method\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "# test_datagen = ImageDataGenerator(\n",
    "#     preprocessing_function=preprocess_input  # Apply ResNet50 preprocessing\n",
    "# )\n",
    "\n",
    "# # Load images from directory\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     train_data_dir,\n",
    "#     target_size=(224, 224),  # Ensure this matches ResNet's expected input size\n",
    "#     batch_size=32,\n",
    "#     class_mode='binary',  # or 'categorical'\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "# validation_generator = test_datagen.flow_from_directory(\n",
    "#     test_data_dir,\n",
    "#     target_size=(224, 224),  # Ensure this matches ResNet's expected input size\n",
    "#     batch_size=32,\n",
    "#     class_mode='binary',  # or 'categorical'\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#     test_set_data_dir,  # replace with your test data path\n",
    "#     target_size=(224, 224),  # or the input size of your model\n",
    "#     batch_size=1,  # or a batch size that divides your total number of test samples\n",
    "#     class_mode='binary',  # or 'categorical' for multi-class\n",
    "#     shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c501182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load pretrained model\n",
    "# base_model = ResNet50(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40789ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add custom layers\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)  # Add a global spatial average pooling layer\n",
    "\n",
    "# # Add a fully connected layer\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# # Add a logistic layer for binary classification\n",
    "# predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# # The model we will train\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "229b9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #freeze layers of pretrained model\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "636837e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Early stopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18ca9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa02b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train the model\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     epochs=100,\n",
    "#     callbacks=[early_stopping],\n",
    "#     validation_data=validation_generator\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f8ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot the loss and accuracy\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming 'history' is the result returned by the fit function\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(len(acc))\n",
    "\n",
    "# plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6384ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Fine-tuning\n",
    "# import tensorflow as tf\n",
    "# # Unfreeze some top layers of the model\n",
    "# for layer in base_model.layers[-20:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# # Re-compile the model for fine-tuning\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # Continue training\n",
    "# history_fine = model.fit(\n",
    "#     train_generator,\n",
    "#     epochs=5,\n",
    "#     validation_data=validation_generator\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5b024a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save model\n",
    "# model.save('C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\resnet.h5')  # Save as HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18f2c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# #Evaluate model on test set\n",
    "# test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "# print(f\"Test Accuracy: {test_accuracy}\")\n",
    "# #calculate f1 score\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# # Predictions\n",
    "# test_predictions = model.predict(test_generator)\n",
    "# test_predictions_binary = (test_predictions > 0.5).astype(np.int64)\n",
    "\n",
    "# # True labels\n",
    "# true_labels = test_generator.classes\n",
    "\n",
    "# # Calculate precision, recall, and F1 score\n",
    "# precision = precision_score(true_labels, test_predictions_binary)\n",
    "# recall = recall_score(true_labels, test_predictions_binary)\n",
    "# f1 = f1_score(true_labels, test_predictions_binary)\n",
    "\n",
    "# print(f\"Precision: {precision}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a275dd",
   "metadata": {},
   "source": [
    "# Apply Saved Models to New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "086d3d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 843ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "[[0.7724255]]\n"
     ]
    }
   ],
   "source": [
    "#apply resnet model to a new image\n",
    "#after training the resnet model in google colab using gpu, I saved the model as resnet2.h5\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Load HDF5 model\n",
    "model = load_model('C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\resnet2.h5')\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'sample2_notflip.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)  # preprocess the image using ResNet's preprocess_input\n",
    "\n",
    "# Predict the class\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "\n",
    "# Predict the class\n",
    "predictions = model.predict(img_array)\n",
    "print(predictions)  # or further process predictions as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "882efaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0.21144961]]\n"
     ]
    }
   ],
   "source": [
    "#apply cnn model to a new image\n",
    "#after training the cnn model in google colab using gpu, I saved the model as cnn.h5\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load HDF5 model\n",
    "model = load_model('C:\\\\Users\\\\Richard Han\\\\Downloads\\\\Apziva MonReader\\\\cnn.h5')\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'sample2_notflip.jpg'\n",
    "img = image.load_img(img_path, target_size=(150,150))\n",
    "img_array = image.img_to_array(img)\n",
    "# Scale the image\n",
    "img_array = img_array / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "\n",
    "# Predict the class\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "\n",
    "# Predict the class\n",
    "predictions = model.predict(img_array)\n",
    "print(predictions)  # or further process predictions as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c4f3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The fine-tuned resnet model appeared to perform better than the cnn model on realistic-looking photos of pages of books; \n",
    "#however, despite both models having high test set accuracy,\n",
    "#they both performed poorly when it came to images that were like stock photos and not as realistic-looking\n",
    "#images of photos of pages of books.  Both models don't seem to generalize well beyond the types of images they were trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1a822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
